{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePokOkwMP9rm"
   },
   "source": [
    "# Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "huXbO1hpiBfz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 17:10:02.271390: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-05 17:10:02.797141: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForTokenClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from seqeval.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RitZN9B6RdGR"
   },
   "source": [
    "# Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "bqXRG3DM10am",
    "outputId": "a09e99a5-a6f5-4a23-9e70-91b450061ee6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oE4OVxV1LLH1"
   },
   "source": [
    "# **Preprocessing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwdutbL7A3zt",
    "outputId": "e1f76707-19c3-47d3-db09-4705663a4702",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 6, 'start_offset': 17, 'end_offset': 28, 'user': 1, 'created_at': '2023-06-14T14:36:46.643706Z', 'updated_at': '2023-06-14T14:36:46.643737Z'}, {'label': 2, 'start_offset': 89, 'end_offset': 91, 'user': 1, 'created_at': '2023-06-14T14:37:01.615695Z', 'updated_at': '2023-06-26T13:46:16.108486Z'}, {'label': 6, 'start_offset': 247, 'end_offset': 258, 'user': 1, 'created_at': '2023-06-14T14:37:39.635439Z', 'updated_at': '2023-06-14T14:37:39.635488Z'}, {'label': 3, 'start_offset': 461, 'end_offset': 475, 'user': 1, 'created_at': '2023-06-14T14:38:01.779370Z', 'updated_at': '2023-06-14T14:38:01.779403Z'}, {'label': 1, 'start_offset': 477, 'end_offset': 481, 'user': 1, 'created_at': '2023-06-14T14:38:12.949077Z', 'updated_at': '2023-06-26T14:45:46.411185Z'}, {'label': 2, 'start_offset': 498, 'end_offset': 500, 'user': 1, 'created_at': '2023-06-14T14:39:21.688854Z', 'updated_at': '2023-06-26T13:46:09.687470Z'}, {'label': 6, 'start_offset': 540, 'end_offset': 551, 'user': 1, 'created_at': '2023-06-14T14:39:34.338738Z', 'updated_at': '2023-06-14T14:39:34.338768Z'}, {'label': 3, 'start_offset': 573, 'end_offset': 580, 'user': 1, 'created_at': '2023-06-14T14:39:42.590250Z', 'updated_at': '2023-06-14T14:39:42.590279Z'}, {'label': 3, 'start_offset': 608, 'end_offset': 615, 'user': 1, 'created_at': '2023-06-14T14:39:47.557756Z', 'updated_at': '2023-06-14T14:39:47.557783Z'}, {'label': 1, 'start_offset': 375, 'end_offset': 379, 'user': 1, 'created_at': '2023-06-14T14:39:54.769686Z', 'updated_at': '2023-06-26T14:45:43.762086Z'}, {'label': 1, 'start_offset': 328, 'end_offset': 332, 'user': 1, 'created_at': '2023-06-14T14:39:59.229334Z', 'updated_at': '2023-06-26T14:45:45.181608Z'}, {'label': 1, 'start_offset': 133, 'end_offset': 137, 'user': 1, 'created_at': '2023-06-26T14:45:06.175675Z', 'updated_at': '2023-06-26T14:45:42.647564Z'}, {'label': 1, 'start_offset': 116, 'end_offset': 131, 'user': 1, 'created_at': '2023-06-26T14:45:08.822924Z', 'updated_at': '2023-06-26T14:45:41.470871Z'}]\n",
      "The influence of γ-radiation on the physical characteristics and sorption properties for Am of the solid extractant AXIONIT MND 40T (TVEX) synthesized by Axion-Rare and Noble Metals JSC (Perm) was studied. With an increase of the absorbed dose of γ-radiation, the granulometric composition, bulk density, and specific volume of TVEX change insignificantly. The IR spectra of TVEX demonstrate significant radiation degradation at an absorbed radiation dose from 1.4 to 2.5 MGy. TVEX is an effective Am sorbent when irradiated to an absorbed γ-radiation dose of no more than 0.6 MGy. At an irradiation dose of 2.5 MGy sorption capacity is significantly reduced.\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "import json\n",
    "\n",
    "\n",
    "#open the file, and format correctly\n",
    "f =open('dataset.jsonl', 'r')\n",
    "json_object = json.dumps(f.readlines(), indent=4)\n",
    "f.close()\n",
    "\n",
    "#save better format into file\n",
    "p = open('sample.txt', 'w')\n",
    "for i in json_object:\n",
    "    p.write(i)\n",
    "p.close()\n",
    "\n",
    "#open new file, and save each \n",
    "j = open('sample.txt', 'r')\n",
    "text = json.loads(j.read())\n",
    "j.close()\n",
    "\n",
    "#compile all json dicts into a list\n",
    "info = []\n",
    "for i in text:\n",
    "    info.append(json.loads(str(i)))\n",
    "    \n",
    "\n",
    "#test it\n",
    "print(info[0]['annotations'])\n",
    "print(info[0]['text'])\n",
    "print(info[0]['annotations'][0]['start_offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeler1(sent, text, annotations):\n",
    "    #sent will be the already parsed sentence, with everything removed\n",
    "    #text will be the straight sentence, info[i]['text']\n",
    "    #annotations will be the list of labels, must be info[i]['annotations']\n",
    "    \n",
    "    #monitor where in the text we are\n",
    "    text_index = 0\n",
    "    \n",
    "    #monitor which word we are in\n",
    "    sent_index = 0\n",
    "    \n",
    "    #keep track of which annotation label we are applying\n",
    "    annotation_index = 0\n",
    "    \n",
    "    #will return all labels for each words\n",
    "    labels = []\n",
    "  \n",
    "    while text_index < len(text) and sent_index < len(sent):\n",
    "        if annotation_index >= len(annotations):\n",
    "            for i in range(len(labels)-1, len(sent)):\n",
    "                labels.append(data_tags[0])\n",
    "                return labels\n",
    "        \n",
    "        #check if we are at the correct index\n",
    "        if text[text_index]== sent[sent_index][0]:\n",
    "            \n",
    "            #double check\n",
    "            if len(sent[sent_index])==1 or text[text_index+1]== sent[sent_index][1]:\n",
    "                \n",
    "                #if not true and the current label aplies to text behind the index behind current, adjest label that you are looking at\n",
    "                if text_index > annotations[annotation_index]['end_offset']:\n",
    "                    annotation_index +=1\n",
    "                    \n",
    "                else:\n",
    "            \n",
    "                    #check if the current text label falls in a label range.\n",
    "                    #if true, apply correct label and move text_index and sent_index\n",
    "                    if text_index >= annotations[annotation_index]['start_offset'] and text_index <= annotations[annotation_index]['end_offset']:\n",
    "                        if len(labels)==0:\n",
    "                            labels.append(data_tags[2*(annotations[annotation_index]['label'])])\n",
    "                        elif labels[-1] == data_tags[2*(annotations[annotation_index]['label'])] or labels[-1] == data_tags[2*(annotations[annotation_index]['label'])-1]:\n",
    "                            labels.append(data_tags[2*(annotations[annotation_index]['label'])])\n",
    "                        else:\n",
    "                            labels.append(data_tags[2*(annotations[annotation_index]['label'])-1])\n",
    "                    \n",
    "                    #if no label applies, apply '0' tag\n",
    "                    else:\n",
    "                        labels.append(data_tags[0])\n",
    "                    \n",
    "                    #adjust which word you are looking at and text_index\n",
    "                    text_index += len(sent[sent_index])\n",
    "                    sent_index += 1\n",
    "                    \n",
    "                \n",
    "            else:\n",
    "                text_index+=1\n",
    "        else:\n",
    "            text_index+=1\n",
    "            \n",
    "            \n",
    "    return labels\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeler2(sent, text, annotations):\n",
    "    #sent will be the already parsed sentence, with everything removed\n",
    "    #text will be the straight sentence, info[i]['text']\n",
    "    #annotations will be the list of labels, must be info[i]['annotations']\n",
    "    \n",
    "    #monitor where in the text we are\n",
    "    text_index = 0\n",
    "    \n",
    "    #keep track of which annotation label we are applying\n",
    "    annotation_index = 0\n",
    "    \n",
    "    #will return all labels for each words\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(0, len(sent)):\n",
    "        if len(annotations) ==0:\n",
    "            return [data_tags[0] for j in range(len(sent[i]))]\n",
    "                    \n",
    "        elif text_index == annotations[annotation_index]['start_offset']:\n",
    "            \n",
    "            labels.append(data_tags[2 * annotations[annotation_index]['label']-1])\n",
    "            \n",
    "        elif text_index >= annotations[annotation_index]['start_offset'] and text_index <= annotations[annotation_index]['end_offset']:\n",
    "            if labels[i-1]==data_tags[0]:\n",
    "                \n",
    "                labels.append(data_tags[2 * annotations[annotation_index]['label']-1])\n",
    "            else:\n",
    "               \n",
    "                labels.append(data_tags[(2 * annotations[annotation_index]['label'] ) ])\n",
    "            \n",
    "        elif text_index > annotations[annotation_index]['end_offset']:\n",
    "            if text_index + 1 == annotations[annotation_index]['start_offset']:\n",
    "                \n",
    "                labels.append(data_tags[2 * annotations[annotation_index]['label']-1])\n",
    "            else: \n",
    "                annotation_index+=1\n",
    "               \n",
    "                labels.append(data_tags[0])\n",
    "                if annotation_index>=len(annotations):\n",
    "                    annotation_index = annotation_index -1\n",
    "        else:\n",
    "        \n",
    "            labels.append(data_tags[0])\n",
    "            \n",
    "        text_index+= (len(sent[i])+1)\n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_in_one (text, annotations):\n",
    "    #text will be the straight sentence, info[i]['text']\n",
    "    #annotations will be the list of labels, must be info[i]['annotations']\n",
    "    \n",
    "    partitions = []\n",
    "    section_labels = []\n",
    "    labels = []\n",
    "    sentences = []\n",
    "    \n",
    "    a_len =  len(annotations)\n",
    "    t_len = len(text)\n",
    "    \n",
    "    if a_len == 0:\n",
    "        sentences = text.split()\n",
    "        for s in sentences:\n",
    "            labels.append(0)\n",
    "        return sentences, labels\n",
    "    \n",
    "    if annotations[0]['start_offset'] == 0:\n",
    "        partitions.append(text[: annotations[0]['end_offset']])\n",
    "        section_labels.append(annotations[0]['label'])\n",
    "    else:\n",
    "        partitions.append(text[: annotations[0]['start_offset']])\n",
    "        section_labels.append(0)\n",
    "        partitions.append(text[annotations[0]['start_offset']: annotations[0]['end_offset']])\n",
    "        section_labels.append(annotations[0]['label'])\n",
    "        \n",
    "        \n",
    "    for i in range(1, a_len -1):\n",
    "        if annotations[i]['start_offset'] == annotations[i-1]['end_offset']:\n",
    "            partitions.append(text[annotations[i]['start_offset']: annotations[i]['end_offset']])\n",
    "            section_labels.append(annotations[i]['label'])\n",
    "        else:\n",
    "            partitions.append(text[annotations[i-1]['end_offset']: annotations[i]['start_offset']])\n",
    "            section_labels.append(0)\n",
    "            partitions.append(text[annotations[i]['start_offset']: annotations[i]['end_offset']])\n",
    "            section_labels.append(annotations[i]['label'])\n",
    "            \n",
    "    \n",
    "    if annotations[a_len-1]['start_offset'] == t_len:\n",
    "        partitions.append(text[annotations[a_len-1]['start_offset']:])\n",
    "        section_labels.append(annotations[a_len-1]['label'])\n",
    "    else:\n",
    "        partitions.append(text[annotations[a_len-1]['start_offset']: annotations[a_len-1]['end_offset']])\n",
    "        section_labels.append(annotations[a_len-1]['label'])\n",
    "        partitions.append(text[annotations[a_len-1]['end_offset']: ])\n",
    "        section_labels.append(0)\n",
    "        \n",
    "        \n",
    "    for i in range(len(section_labels)):\n",
    "        p_split = partitions[i].split()\n",
    "        p_len = len(p_split)\n",
    "        if p_len > 0:\n",
    "            sentences.extend(p_split)\n",
    "            if section_labels[i] == 0:\n",
    "                for p in p_split:\n",
    "                    labels.append(0)\n",
    "            else:\n",
    "                labels.append(data_tags[2 * section_labels[i] -1])\n",
    "                for j in range(1, p_len):\n",
    "                     labels.append(data_tags[2 * section_labels[i]])\n",
    "                    \n",
    "        \n",
    "    \n",
    "        \n",
    "    return sentences, labels\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "90bfea074fb74029988d843be156887d",
      "a73c84059bc649f8b21c25f32662de32",
      "2042a2bd748246de8e33be4c188715ca",
      "79e1052f1ce14de09b93b29f36fcdf26",
      "b14647f6aae14ecc8a519df754f03037",
      "d1144a9b389f47df90b5c127031bfd3a",
      "5cd5dba2aea04e8ab8f4d6571e1d8ad7",
      "f8753b1167d24669982f270213629a70"
     ]
    },
    "id": "qhpKOKSr136j",
    "outputId": "3d599ff1-d06d-43ec-cf91-053d8f241bdf"
   },
   "outputs": [],
   "source": [
    "# To use the BERT, you must use the BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased', do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def splitter1():\n",
    "    return [re.findall(r\"[\\w']+\", info[i]['text']) for i in range(len(info))]\n",
    "\n",
    "def splitter2():\n",
    "    return [info[i]['text'].split() for i in range(len(info))]\n",
    "    \n",
    "def splitter3():\n",
    "    l = []\n",
    "    for i in range(len(info)):\n",
    "        sent = tokenizer.tokenize(info[i]['text'])\n",
    "        for i in range(len(sent)):\n",
    "            if sent[i][0]=='#':\n",
    "                sent[i] = sent[i][2:]\n",
    "        print(sent)       \n",
    "        l.append(sent)\n",
    "    return l\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processor(splitmethod, labelmethod):\n",
    "    s = splitmethod()\n",
    "    \n",
    "    l=[]\n",
    "\n",
    "    for i in range(len(s)):\n",
    "        l.append(labelmethod(s[i], info[i]['text'], info[i]['annotations'] ))\n",
    "    \n",
    "    return s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'influence', 'of', 'γ', '-', 'radiation', 'on', 'the', 'physical', 'characteristics', 'and', 'sorption', 'properties', 'for', 'am', 'of', 'the', 'solid', 'extract', '##ant', 'axi', '##onit', 'mn', '##d', '40', '##t', '(', 'tv', '##ex', ')', 'synthesized', 'by', 'axi', '##on', '-', 'rare', 'and', 'noble', 'metals', 'js', '##c', '(', 'perm', ')', 'was', 'studied', '.', 'with', 'an', 'increase', 'of', 'the', 'absorbed', 'dose', 'of', 'γ', '-', 'radiation', ',', 'the', 'granul', '##ometric', 'composition', ',', 'bulk', 'density', ',', 'and', 'specific', 'volume', 'of', 'tv', '##ex', 'change', 'insignificant', '##ly', '.', 'the', 'ir', 'spectra', 'of', 'tv', '##ex', 'demonstrate', 'significant', 'radiation', 'degradation', 'at', 'an', 'absorbed', 'radiation', 'dose', 'from', '1', '.', '4', 'to', '2', '.', '5', 'mg', '##y', '.', 'tv', '##ex', 'is', 'an', 'effective', 'am', 'sor', '##ben', '##t', 'when', 'irradiated', 'to', 'an', 'absorbed', 'γ', '-', 'radiation', 'dose', 'of', 'no', 'more', 'than', '0', '.', '6', 'mg', '##y', '.', 'at', 'an', 'irradiation', 'dose', 'of', '2', '.', '5', 'mg', '##y', 'sorption', 'capacity', 'is', 'significantly', 'reduced', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(info[0]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels\n",
    "data_tags = ['0','C', 'C-cont' , 'M', 'M-cont', 'Q', 'Q-cont', 'T' , 'T-cont', 'A' , 'A-cont', 'R', 'R-cont']\n",
    "\n",
    "\n",
    "\n",
    "sentences, labels = [], []\n",
    "for i in range(len(info)):\n",
    "    s, l = all_in_one(info[i]['text'], info[i]['annotations'])\n",
    "    sentences.append(s)\n",
    "    labels.append(l)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "iipz8_yRZ39E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'C', 'C-cont', 'M', 'M-cont', 'Q', 'Q-cont', 'T', 'T-cont', 'A', 'A-cont', 'R', 'R-cont']\n",
      "['0', 'C', 'C-cont', 'M', 'M-cont', 'Q', 'Q-cont', 'T', 'T-cont', 'A', 'A-cont', 'R', 'R-cont', 'PAD']\n",
      "{'0': 0, 'C': 1, 'C-cont': 2, 'M': 3, 'M-cont': 4, 'Q': 5, 'Q-cont': 6, 'T': 7, 'T-cont': 8, 'A': 9, 'A-cont': 10, 'R': 11, 'R-cont': 12, 'PAD': 13}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Determine the list of tags\n",
    "tag_values = data_tags\n",
    "print(tag_values)\n",
    "\n",
    "tag_values.append(\"PAD\")\n",
    "print(tag_values)\n",
    "\n",
    "tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
    "print(tag2idx)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXahgP-Vao7q",
    "outputId": "1b6313f7-b619-4a2b-e714-8f585a8f3b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments 0\n",
      "were 0\n",
      "performed 0\n",
      "with 0\n",
      "t 0\n",
      "riamylphosphine A\n",
      "oxide A-cont\n",
      "( 0\n",
      "TAPO A\n",
      "), 0\n",
      "octyl(phenyl)-N,N-diisobutylcarbamoylmethylphosphine A\n",
      "oxide A-cont\n",
      "( 0\n",
      "CMPO A\n",
      "Eu(NO3)3·6H2O C\n",
      "(Vekton, 0\n",
      "Russia). 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(labels[99])):\n",
    "    print(sentences[99][i],labels[99][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqdCmpI0XWbN",
    "outputId": "2f94e3d1-7416-4f05-f2ff-51651567bad4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "4UEvE5GD19Yp"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels):\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    for word, label in zip(sentence, text_labels):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "SOZqX8q52BOr"
   },
   "outputs": [],
   "source": [
    "tokenized_texts_and_labels = [ tokenize_and_preserve_labels(sent, labs) for sent, labs in zip(sentences, labels)]\n",
    "\n",
    "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
    "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7pJxaAwrXMCr"
   },
   "outputs": [],
   "source": [
    "# MAX_LEN is the maximum length of a sequence\n",
    "MAX_LEN = 64 # 64 or 128 or ...\n",
    "bs = 5 # batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ACWaTEQ12T_q"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use Padding to equalize the length of sentences\u001b[39;00m\n\u001b[1;32m      2\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m pad_sequences([tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(txt) \u001b[38;5;28;01mfor\u001b[39;00m txt \u001b[38;5;129;01min\u001b[39;00m tokenized_texts],\n\u001b[1;32m      3\u001b[0m                           maxlen\u001b[38;5;241m=\u001b[39mMAX_LEN, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m      4\u001b[0m                           truncating\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtag2idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlab\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlab\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtag2idx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlong\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/keras_preprocessing/sequence.py:98\u001b[0m, in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTruncating type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     95\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot understood\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m truncating)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# check `trunc` has expected shape\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m trunc \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trunc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m!=\u001b[39m sample_shape:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of sample \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m of sequence at position \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    101\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis different from expected shape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    102\u001b[0m                      (trunc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:], idx, sample_shape))\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Use Padding to equalize the length of sentences\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
    "                          truncating=\"post\", padding=\"post\")\n",
    "\n",
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HK8j0_fU2Xc7"
   },
   "outputs": [],
   "source": [
    "# Do not mask values that are zero\n",
    "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MgKNvMf2e4x"
   },
   "outputs": [],
   "source": [
    "# Split data to train and validation. %90 for train and %10 for validation\n",
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "\n",
    "# Each mask contains 10% of a sentence\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)\n",
    "\n",
    "# The input of the BERT should be the tensors produced using PyTorch\n",
    "# So convert all inputs and labels into torch tensors\n",
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "print(train_sampler)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIlayjaxK1ac"
   },
   "source": [
    "# **Build model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218,
     "referenced_widgets": [
      "185d34a6bb6b4439814040da0f2853dc",
      "c1cd492626094c28a241545b0fd13a58",
      "04bec66c474c43b2abf55df9493c1ad3",
      "28c5ada5e413494d875958479bce1bf8",
      "153c7c4195394cd987cd27224c076792",
      "0aa2f68932aa46e08d79b503cdb066d5",
      "e8ccc221de014f9589d4c01db1576bee",
      "a21058481d204b6a98739c21527b9b53",
      "3a57498cc92f475289ed438778ad901a",
      "339741a64cde4ae781225b14a9c2cb76",
      "53b2be4adc4e42879082de9dc5e7e288",
      "93df6238747f46a687b94eaa17a756f2",
      "0e77fed9e8004154922761880363a58f",
      "e51c5802ddc848b68a80aa74f8ac7c81",
      "cf5ab30e45634ad8834f8ba8130e11ad",
      "8c7006c2c348458d881cd0f82191e03c"
     ]
    },
    "id": "wruwJ-wz4HxW",
    "outputId": "193933c8-307c-4f72-92c0-98cabc3f134b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load BERT Model\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"allenai/scibert_scivocab_uncased\",\n",
    "    num_labels=len(tag2idx), # The number of output labels\n",
    "    output_attentions = False, # Whether the model returns attention weights.\n",
    "    output_hidden_states = False # Whether the model returns all hidden-states.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WybQNyPM4Ks0"
   },
   "outputs": [],
   "source": [
    "# Tell PyTorch to run this model on the GPU\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhWWhnfV4Vl-"
   },
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr= 5e-7, # learning-rate default is 3e-5\n",
    "    eps=1e-8 # adam-epsilon default is 1e-8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKuYyYbY4dJP"
   },
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POhQTWIpJwlb"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74x245VwbjzK"
   },
   "outputs": [],
   "source": [
    "def acc(print_labels):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "\n",
    "        tokenized_sentence = tokenizer.encode(sentences[i])\n",
    "        input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids)\n",
    "\n",
    "        label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "\n",
    "        # join bpe split tokens\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "        new_tokens, new_labels = [], []\n",
    "        for token, label_idx in zip(tokens, label_indices[0]):\n",
    "            if token.startswith(\"##\"):\n",
    "                new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "            else:\n",
    "                new_labels.append(tag_values[label_idx])\n",
    "                new_tokens.append(token)\n",
    "\n",
    "        new_labels = new_labels[1:-2]\n",
    "        accuracy_list.append(accuracy_score(new_labels, labels[i]))\n",
    "        if print_labels == True:\n",
    "            print(\"\\nPredict labels: \",new_labels)\n",
    "            print(\"Actual labels: \",labels[i])\n",
    "\n",
    "    return statistics.mean(accuracy_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7I9lOiM94kKg",
    "outputId": "eac63c54-d19d-4261-8de8-1ef85d09fb77"
   },
   "outputs": [],
   "source": [
    "## Store the average loss after each epoch so we can plot them.\n",
    "import copy\n",
    "loss_values, validation_loss_values = [], []\n",
    "\n",
    "test_acc = []\n",
    "\n",
    "max_test = 0\n",
    "\n",
    "for e in trange(epochs, desc=\"Epoch\"):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Always clear any previously calculated gradients before performing a backward pass.\n",
    "        model.zero_grad()\n",
    "        # forward pass\n",
    "        # This will return the loss (rather than the model output)\n",
    "        # because we have provided the `labels`.\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask, labels=b_labels)\n",
    "        # get the loss\n",
    "        loss = outputs[0]\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        total_loss += loss.item()\n",
    "        # Clip the norm of the gradient\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(\"\\nAverage train loss: {}\".format(avg_train_loss))\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    # Put the model into evaluation mode\n",
    "    model.eval()\n",
    "    # Reset the validation loss for this epoch.\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients,\n",
    "        # saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have not provided labels.\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "                            attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Move logits and labels to CPU\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    eval_loss = eval_loss / len(valid_dataloader)\n",
    "    validation_loss_values.append(eval_loss)\n",
    "    print(\"\\nValidation loss: {}\".format(eval_loss))\n",
    "    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
    "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
    "    valid_tags = [tag_values[l_i] for l in true_labels\n",
    "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
    "\n",
    "    print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
    "    #print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n",
    "    print()\n",
    "    a = acc(False)\n",
    "    test_acc.append(a)\n",
    "    if a * .97 >= max_test:\n",
    "        max_test = a\n",
    "        torch.save(model, \"test.ck\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "DY0dJeiF5Xao",
    "outputId": "ff5516fd-e7c1-4817-a764-1709cf212126"
   },
   "outputs": [],
   "source": [
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o', label=\"training loss\")\n",
    "plt.plot(validation_loss_values, 'r-o', label=\"validation loss\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOYQWNFEJeHC"
   },
   "source": [
    "# Performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WcmlxmjWXz2",
    "outputId": "77aade8e-a9ce-4e06-dfb7-2055864ddc57"
   },
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(test_acc, 'b-o', label=\"test accuracy\")\n",
    "\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, labels = processor(splitter2, labeler2)\n",
    "\n",
    "acc(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0B82QAERQMpJ",
    "outputId": "9874451d-4769-408a-d83c-72cbca107e97"
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"test.ck\")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "sentences, labels = processor(splitter1, labeler1)\n",
    "print(acc(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, labels = processor(splitter2, labeler2)\n",
    "\n",
    "acc(True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NZDhhU5ZP1oC",
    "ePokOkwMP9rm",
    "RitZN9B6RdGR",
    "oE4OVxV1LLH1",
    "fIlayjaxK1ac",
    "POhQTWIpJwlb",
    "cOYQWNFEJeHC"
   ],
   "name": "NER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04bec66c474c43b2abf55df9493c1ad3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0aa2f68932aa46e08d79b503cdb066d5",
      "max": 440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_153c7c4195394cd987cd27224c076792",
      "value": 440
     }
    },
    "0aa2f68932aa46e08d79b503cdb066d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e77fed9e8004154922761880363a58f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "153c7c4195394cd987cd27224c076792": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "185d34a6bb6b4439814040da0f2853dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_04bec66c474c43b2abf55df9493c1ad3",
       "IPY_MODEL_28c5ada5e413494d875958479bce1bf8"
      ],
      "layout": "IPY_MODEL_c1cd492626094c28a241545b0fd13a58"
     }
    },
    "2042a2bd748246de8e33be4c188715ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1144a9b389f47df90b5c127031bfd3a",
      "max": 1198122,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b14647f6aae14ecc8a519df754f03037",
      "value": 1198122
     }
    },
    "28c5ada5e413494d875958479bce1bf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a21058481d204b6a98739c21527b9b53",
      "placeholder": "​",
      "style": "IPY_MODEL_e8ccc221de014f9589d4c01db1576bee",
      "value": " 440/440 [00:00&lt;00:00, 734B/s]"
     }
    },
    "339741a64cde4ae781225b14a9c2cb76": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a57498cc92f475289ed438778ad901a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53b2be4adc4e42879082de9dc5e7e288",
       "IPY_MODEL_93df6238747f46a687b94eaa17a756f2"
      ],
      "layout": "IPY_MODEL_339741a64cde4ae781225b14a9c2cb76"
     }
    },
    "53b2be4adc4e42879082de9dc5e7e288": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e51c5802ddc848b68a80aa74f8ac7c81",
      "max": 654226731,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e77fed9e8004154922761880363a58f",
      "value": 654226731
     }
    },
    "5cd5dba2aea04e8ab8f4d6571e1d8ad7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79e1052f1ce14de09b93b29f36fcdf26": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8753b1167d24669982f270213629a70",
      "placeholder": "​",
      "style": "IPY_MODEL_5cd5dba2aea04e8ab8f4d6571e1d8ad7",
      "value": " 1.20M/1.20M [00:03&lt;00:00, 353kB/s]"
     }
    },
    "8c7006c2c348458d881cd0f82191e03c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90bfea074fb74029988d843be156887d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2042a2bd748246de8e33be4c188715ca",
       "IPY_MODEL_79e1052f1ce14de09b93b29f36fcdf26"
      ],
      "layout": "IPY_MODEL_a73c84059bc649f8b21c25f32662de32"
     }
    },
    "93df6238747f46a687b94eaa17a756f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c7006c2c348458d881cd0f82191e03c",
      "placeholder": "​",
      "style": "IPY_MODEL_cf5ab30e45634ad8834f8ba8130e11ad",
      "value": " 654M/654M [00:19&lt;00:00, 34.4MB/s]"
     }
    },
    "a21058481d204b6a98739c21527b9b53": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a73c84059bc649f8b21c25f32662de32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b14647f6aae14ecc8a519df754f03037": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c1cd492626094c28a241545b0fd13a58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf5ab30e45634ad8834f8ba8130e11ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1144a9b389f47df90b5c127031bfd3a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e51c5802ddc848b68a80aa74f8ac7c81": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8ccc221de014f9589d4c01db1576bee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8753b1167d24669982f270213629a70": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
